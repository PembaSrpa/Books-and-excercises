{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48df989",
   "metadata": {},
   "source": [
    "# Text Analysis and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import random\n",
    "\n",
    "def split_line(line):\n",
    "    \"\"\"Replaces em-dashes with spaces and splits a string into a list of words.\"\"\"\n",
    "    return line.replace('—', ' ').split()\n",
    "\n",
    "def get_punctuation(filename):\n",
    "    \"\"\"Identifies all punctuation characters in a file using the Unicode database.\"\"\"\n",
    "    punc_marks = {}\n",
    "    for line in open(filename):\n",
    "        for char in line:\n",
    "            category = unicodedata.category(char)\n",
    "            if category.startswith('P'):\n",
    "                punc_marks[char] = 1\n",
    "    return ''.join(punc_marks)\n",
    "\n",
    "def clean_word(word, punctuation):\n",
    "    \"\"\"Strips specified punctuation from word edges and converts to lowercase.\"\"\"\n",
    "    return word.strip(punctuation).lower()\n",
    "\n",
    "def build_word_counter(filename, punctuation):\n",
    "    \"\"\"Builds a frequency histogram of all cleaned words in a text file.\"\"\"\n",
    "    word_counter = {}\n",
    "    for line in open(filename):\n",
    "        for word in split_line(line):\n",
    "            word = clean_word(word, punctuation)\n",
    "            word_counter[word] = word_counter.get(word, 0) + 1\n",
    "    return word_counter\n",
    "\n",
    "def second_element(t):\n",
    "    \"\"\"Returns the second element of a tuple for sorting by dictionary values.\"\"\"\n",
    "    return t[1]\n",
    "\n",
    "def print_most_common(word_counter, num=5):\n",
    "    \"\"\"Prints the most frequent items from a dictionary using an optional parameter.\"\"\"\n",
    "    items = sorted(word_counter.items(), key=second_element, reverse=True)\n",
    "    for word, freq in items[:num]:\n",
    "        print(freq, word, sep='\\t')\n",
    "\n",
    "def subtract(d1, d2):\n",
    "    \"\"\"Returns a dictionary containing keys from d1 that are absent in d2.\"\"\"\n",
    "    res = {}\n",
    "    for key in d1:\n",
    "        if key not in d2:\n",
    "            res[key] = d1[key]\n",
    "    return res\n",
    "\n",
    "def choose_from_hist(hist):\n",
    "    \"\"\"Selects a random word weighted by its frequency in a histogram.\"\"\"\n",
    "    t = []\n",
    "    for word, freq in hist.items():\n",
    "        t.extend([word] * freq)\n",
    "    return random.choice(t)\n",
    "\n",
    "def add_bigram(bigram, successor_map):\n",
    "    \"\"\"Adds a two-word sequence to a mapping using the setdefault method.\"\"\"\n",
    "    first, second = bigram\n",
    "    successor_map.setdefault(first, []).append(second)\n",
    "\n",
    "def shift(prefix, word):\n",
    "    \"\"\"Creates a new prefix tuple by shifting out the head and adding a new word.\"\"\"\n",
    "    return prefix[1:] + (word,)\n",
    "\n",
    "def generate_text(mapping, n=50):\n",
    "    \"\"\"Generates random text by following bigram transitions in a successor map.\"\"\"\n",
    "    if not mapping:\n",
    "        return\n",
    "\n",
    "    bigram = random.choice(list(mapping.keys()))\n",
    "    for _ in range(n):\n",
    "        suffixes = mapping.get(bigram)\n",
    "        if not suffixes:\n",
    "            break\n",
    "        word = random.choice(suffixes)\n",
    "        print(word, end=' ')\n",
    "        bigram = (bigram[1], word)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ca93c8",
   "metadata": {},
   "source": [
    "### What are the differences between large language models like ChatGPT and Markov chain text analysis?\n",
    "\n",
    "While Markov chains and Large Language Models (LLMs) both generate text by predicting the next word in a sequence, they differ fundamentally in context, representation, and complexity. A Markov chain is \"memoryless,\" relying on a dictionary of exact string matches (like the successor_map) that only considers a tiny window of previous words—typically just one or two—often leading to nonsensical results as the chain grows. In contrast, LLMs use Transformers and Attention Mechanisms to maintain a \"memory\" of thousands of words, and they process language through Word Embeddings—mathematical vectors that represent the semantic meaning and relationship between words rather than just their spelling. Consequently, while a Markov chain can only repeat patterns found explicitly in its source text, an LLM can reason, understand context, and generate entirely original, coherent responses based on a deep statistical understanding of human language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ae059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that counts the number of times each trigram (sequence of three words) appears.\n",
    "\n",
    "def count_trigram(trigram, trigram_map):\n",
    "    \"\"\"Adds a trigram to the mapping and updates its frequency.\"\"\"\n",
    "    prefix = (trigram[0], trigram[1])\n",
    "    suffix = trigram[2]\n",
    "\n",
    "    hist = trigram_map.setdefault(prefix, {})\n",
    "    hist[suffix] = hist.get(suffix, 0) + 1\n",
    "\n",
    "def process_word_trigram(filename):\n",
    "    \"\"\"Reads a file and builds a mapping of trigram frequencies.\"\"\"\n",
    "    trigram_map = {}\n",
    "    words = []\n",
    "\n",
    "    for line in open(filename):\n",
    "        for word in split_line(line):\n",
    "            words.append(clean_word(word))\n",
    "\n",
    "    for i in range(len(words) - 2):\n",
    "        trigram = (words[i], words[i+1], words[i+2])\n",
    "        count_trigram(trigram, trigram_map)\n",
    "\n",
    "    return trigram_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function called add_trigram that takes a list of three words and either adds or updates an item in successor_map, using the first two words as the key and the third word as a possible successor.\n",
    "\n",
    "def add_trigram(window):\n",
    "    \"\"\"\n",
    "    Takes a list of three words.\n",
    "    Uses the first two as a tuple key and adds the third to the successor list.\n",
    "    \"\"\"\n",
    "    prefix = tuple(window[:2])\n",
    "    suffix = window[2]\n",
    "\n",
    "    successor_map.setdefault(prefix, []).append(suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db6469",
   "metadata": {},
   "source": [
    "### Write a loop that generates 50 more words by following these steps:\n",
    "1. In successor_map, look up the list of words that can follow bigram.\n",
    "2. Choose one of them at random and print it.\n",
    "3. For the next iteration, make a new bigram that contains the second word from\n",
    "bigram and the chosen successor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b35c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sat "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "successor_map = { ('the', 'cat'): ['sat', 'jumped'],}\n",
    "successors = list(successor_map)\n",
    "bigram = random.choice(successors)\n",
    "\n",
    "for i in range(50):\n",
    "    possible_suffixes = successor_map.get(bigram)\n",
    "\n",
    "    if not possible_suffixes:\n",
    "        break\n",
    "\n",
    "    next_word = random.choice(possible_suffixes)\n",
    "    print(next_word, end=' ')\n",
    "\n",
    "    bigram = (bigram[1], next_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
